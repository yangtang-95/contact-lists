{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "455e0692-acfd-45c7-8732-ecd5456fa315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please close the popup within the next 5 seconds...\n",
      "Scraping page 1\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "Error extracting link: I/O operation on closed file.\n",
      "No more pages or error: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=127.0.6533.120)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00BB8923+23283]\n",
      "\t(No symbol) [0x00B7E934]\n",
      "\t(No symbol) [0x00AB0733]\n",
      "\t(No symbol) [0x00A8D2E3]\n",
      "\t(No symbol) [0x00B1A64F]\n",
      "\t(No symbol) [0x00B2C686]\n",
      "\t(No symbol) [0x00B141B6]\n",
      "\t(No symbol) [0x00AE8017]\n",
      "\t(No symbol) [0x00AE890D]\n",
      "\tGetHandleVerifier [0x00CAA5F3+1013699]\n",
      "\tGetHandleVerifier [0x00CB3E4C+1052700]\n",
      "\tGetHandleVerifier [0x00CAD4B4+1025668]\n",
      "\tGetHandleVerifier [0x00BDEA2B+179195]\n",
      "\t(No symbol) [0x00B86833]\n",
      "\t(No symbol) [0x00B83198]\n",
      "\t(No symbol) [0x00B83337]\n",
      "\t(No symbol) [0x00B7B4BE]\n",
      "\tBaseThreadInitThunk [0x76377BA9+25]\n",
      "\tRtlInitializeExceptionChain [0x7707C10B+107]\n",
      "\tRtlClearBits [0x7707C08F+191]\n",
      "\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=127.0.6533.120)\nStacktrace:\n\tGetHandleVerifier [0x00BB8923+23283]\n\t(No symbol) [0x00B7E934]\n\t(No symbol) [0x00AB0733]\n\t(No symbol) [0x00A8D2E3]\n\t(No symbol) [0x00B1A64F]\n\t(No symbol) [0x00B2C686]\n\t(No symbol) [0x00B141B6]\n\t(No symbol) [0x00AE8017]\n\t(No symbol) [0x00AE890D]\n\tGetHandleVerifier [0x00CAA5F3+1013699]\n\tGetHandleVerifier [0x00CB3E4C+1052700]\n\tGetHandleVerifier [0x00CAD4B4+1025668]\n\tGetHandleVerifier [0x00BDEA2B+179195]\n\t(No symbol) [0x00B86833]\n\t(No symbol) [0x00B83198]\n\t(No symbol) [0x00B83337]\n\t(No symbol) [0x00B7B4BE]\n\tBaseThreadInitThunk [0x76377BA9+25]\n\tRtlInitializeExceptionChain [0x7707C10B+107]\n\tRtlClearBits [0x7707C08F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m         extract_product_links()\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Scrape all pages\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m scrape_all_pages()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Close the browser\u001b[39;00m\n\u001b[0;32m     69\u001b[0m driver\u001b[38;5;241m.\u001b[39mquit()\n",
      "Cell \u001b[1;32mIn[23], line 58\u001b[0m, in \u001b[0;36mscrape_all_pages\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Navigate to the second page directly if there are more pages\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://growershouse.com/indoor-led-grow-lights?p=2&product_list_limit=96\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)  \u001b[38;5;66;03m# Wait for the new page to load\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNavigated to the second page\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:363\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a web page in the current browser session.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m\"\u001b[39m: url})\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:354\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n\u001b[0;32m    355\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=127.0.6533.120)\nStacktrace:\n\tGetHandleVerifier [0x00BB8923+23283]\n\t(No symbol) [0x00B7E934]\n\t(No symbol) [0x00AB0733]\n\t(No symbol) [0x00A8D2E3]\n\t(No symbol) [0x00B1A64F]\n\t(No symbol) [0x00B2C686]\n\t(No symbol) [0x00B141B6]\n\t(No symbol) [0x00AE8017]\n\t(No symbol) [0x00AE890D]\n\tGetHandleVerifier [0x00CAA5F3+1013699]\n\tGetHandleVerifier [0x00CB3E4C+1052700]\n\tGetHandleVerifier [0x00CAD4B4+1025668]\n\tGetHandleVerifier [0x00BDEA2B+179195]\n\t(No symbol) [0x00B86833]\n\t(No symbol) [0x00B83198]\n\t(No symbol) [0x00B83337]\n\t(No symbol) [0x00B7B4BE]\n\tBaseThreadInitThunk [0x76377BA9+25]\n\tRtlInitializeExceptionChain [0x7707C10B+107]\n\tRtlClearBits [0x7707C08F+191]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Set up the Chrome driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "# URL of the first page to scrape\n",
    "url = 'https://growershouse.com/indoor-led-grow-lights?product_list_limit=96'\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for 5 seconds to allow manual closing of the popup\n",
    "print(\"Please close the popup within the next 5 seconds...\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Open a CSV file to write product links\n",
    "with open('product_links.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Product Link'])  # Write header\n",
    "\n",
    "    # Function to extract product links\n",
    "    def extract_product_links():\n",
    "        products = driver.find_elements(By.CLASS_NAME, 'item.product.product-item')\n",
    "        for product in products:\n",
    "            try:\n",
    "                # Extract the link\n",
    "                link = product.find_element(By.TAG_NAME, 'a').get_attribute('href')\n",
    "                writer.writerow([link])  # Write link to CSV\n",
    "            except Exception as e:\n",
    "                print(f'Error extracting link: {e}')\n",
    "\n",
    "    # Function to handle pagination by directly navigating to the next page\n",
    "    def scrape_all_pages():\n",
    "        page_number = 1\n",
    "        while True:\n",
    "            print(f\"Scraping page {page_number}\")\n",
    "            extract_product_links()\n",
    "\n",
    "            # Try to find the \"Next\" button\n",
    "            try:\n",
    "                next_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, '.pages-item-next a.link.next'))\n",
    "                )\n",
    "                # If found, click it\n",
    "                next_button.click()\n",
    "                time.sleep(3)  # Wait for the new page to load\n",
    "                page_number += 1\n",
    "            except Exception as e:\n",
    "                print(f'No more pages or error: {e}')\n",
    "                break\n",
    "\n",
    "        # Navigate to the second page directly if there are more pages\n",
    "        driver.get('https://growershouse.com/indoor-led-grow-lights?p=2&product_list_limit=96')\n",
    "        time.sleep(3)  # Wait for the new page to load\n",
    "        print(\"Navigated to the second page\")\n",
    "\n",
    "        # Continue scraping from the second page\n",
    "        extract_product_links()\n",
    "\n",
    "# Scrape all pages\n",
    "scrape_all_pages()\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "https://growershouse.com/indoor-led-grow-lights?p=2&product_list_limit=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd861df-9d92-49fb-b4c4-e50d2ef1cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Set up the Chrome driver with rotating user-agents\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.101 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:47.0) Gecko/20100101 Firefox/47.0\",\n",
    "    # Add more user agents if needed\n",
    "]\n",
    "\n",
    "# Randomly select a user-agent for each session\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(f\"user-agent={random.choice(user_agents)}\")\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Read the CSV file with product links\n",
    "product_links_df = pd.read_csv('product_links.csv')\n",
    "product_urls = product_links_df['Product Link'].tolist()\n",
    "\n",
    "# Step 1: Collect all possible specification names\n",
    "all_spec_names = set()\n",
    "\n",
    "def random_pause():\n",
    "    pause_time = random.uniform(2, 10)  # Random pause between 2 to 10 seconds\n",
    "    time.sleep(pause_time)\n",
    "\n",
    "def collect_spec_names(url):\n",
    "    driver.get(url)\n",
    "    random_pause()  # Pause before scraping\n",
    "    time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "    specs_section = driver.find_elements(By.CSS_SELECTOR, 'div.additional-attributes-wrapper table tr')\n",
    "    for row in specs_section:\n",
    "        spec_name = row.find_element(By.TAG_NAME, 'th').text\n",
    "        all_spec_names.add(spec_name)\n",
    "\n",
    "for url in product_urls:\n",
    "    collect_spec_names(url)\n",
    "\n",
    "# Convert spec names to a list for consistent ordering\n",
    "all_spec_names = list(all_spec_names)\n",
    "\n",
    "# Initialize an empty DataFrame with all possible columns\n",
    "df = pd.DataFrame(columns=['Product Name', 'Product Description', 'Price'] + all_spec_names)\n",
    "\n",
    "# Step 2: Scrape the product details and append to the DataFrame\n",
    "def scrape_product_details(url):\n",
    "    driver.get(url)\n",
    "    random_pause()  # Pause before scraping\n",
    "    time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "    product_data = {name: '' for name in all_spec_names}  # Initialize with all possible spec names\n",
    "\n",
    "    # Extract the product name\n",
    "    product_name = driver.find_element(By.CLASS_NAME, 'page-title').text\n",
    "    product_data['Product Name'] = product_name\n",
    "\n",
    "    # Extract the product description\n",
    "    product_description = driver.find_element(By.CLASS_NAME, 'product.attribute.overview').text\n",
    "    product_data['Product Description'] = product_description\n",
    "\n",
    "    # Extract specifications from the \"additional-attributes-wrapper\" class\n",
    "    specs_section = driver.find_elements(By.CSS_SELECTOR, 'div.additional-attributes-wrapper table tr')\n",
    "    for row in specs_section:\n",
    "        spec_name = row.find_element(By.TAG_NAME, 'th').text\n",
    "        spec_value = row.find_element(By.TAG_NAME, 'td').text\n",
    "        product_data[spec_name] = spec_value\n",
    "\n",
    "    # Extract the price, if available\n",
    "    try:\n",
    "        price = driver.find_element(By.CLASS_NAME, 'price').text\n",
    "        product_data['Price'] = price\n",
    "    except:\n",
    "        product_data['Price'] = 'Not listed'\n",
    "\n",
    "    return product_data\n",
    "\n",
    "# Scrape each product and add to the DataFrame\n",
    "for url in product_urls:\n",
    "    product_details = scrape_product_details(url)\n",
    "    df = df.append(product_details, ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('dynamic_product_details.csv', index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f451d1-964d-4850-9338-55ca4c405de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
