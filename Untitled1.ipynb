{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71d6d5b2-1eec-4d69-b55d-4b31c971acd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved as Updated_Toronto_Energy_Audit_Companies_Links.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def search_linkedin(company_name):\n",
    "    search_url = f\"https://www.google.com/search?q={company_name.replace(' ', '+')}+linkedin\"\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        if \"linkedin.com/company\" in a['href'] or \"linkedin.com/in\" in a['href']:\n",
    "            linkedin_url = re.search(\"(?P<url>https?://[^\\s]+)\", a['href'])\n",
    "            if linkedin_url:\n",
    "                linkedin_url = linkedin_url.group(\"url\")\n",
    "                linkedin_url = linkedin_url.split('&')[0]\n",
    "                return linkedin_url\n",
    "    return None\n",
    "\n",
    "def search_facebook(company_name):\n",
    "    search_url = f\"https://www.google.com/search?q={company_name.replace(' ', '+')}+facebook\"\n",
    "    response = requests.get(search_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        if \"facebook.com\" in a['href']:\n",
    "            facebook_url = re.search(\"(?P<url>https?://[^\\s]+)\", a['href'])\n",
    "            if facebook_url:\n",
    "                facebook_url = facebook_url.group(\"url\")\n",
    "                facebook_url = facebook_url.split('&')[0]\n",
    "                return facebook_url\n",
    "    return None\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"developers and related compaies - Sheet1.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize columns for LinkedIn and Facebook pages if they do not exist and set them to string type\n",
    "if \"LinkedIn Page\" not in df.columns:\n",
    "    df[\"LinkedIn Page\"] = \"\"\n",
    "if \"Facebook Page\" not in df.columns:\n",
    "    df[\"Facebook Page\"] = \"\"\n",
    "\n",
    "df[\"LinkedIn Page\"] = df[\"LinkedIn Page\"].astype(str)\n",
    "df[\"Facebook Page\"] = df[\"Facebook Page\"].astype(str)\n",
    "\n",
    "# Update the LinkedIn and Facebook pages\n",
    "for index, row in df.iterrows():\n",
    "    company_name = row[\"Company Name\"]\n",
    "    linkedin_url = search_linkedin(company_name)\n",
    "    facebook_url = search_facebook(company_name)\n",
    "    df.at[index, \"LinkedIn Page\"] = linkedin_url if linkedin_url else \"Not Found\"\n",
    "    df.at[index, \"Facebook Page\"] = facebook_url if facebook_url else \"Not Found\"\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "updated_file_path = \"Updated_Toronto_Energy_Audit_Companies_Links.csv\"\n",
    "df.to_csv(updated_file_path, index=False)\n",
    "\n",
    "print(f\"Updated file saved as {updated_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ba4da18-f22b-4f3e-bc74-5c20156ae572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved as Cleaned_Company_List.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the new CSV file\n",
    "new_file_path = \"Updated_Toronto_Energy_Audit_Companies_Links.csv\"  # Replace with the actual path to your new CSV file\n",
    "df_new = pd.read_csv(new_file_path)\n",
    "\n",
    "# Drop duplicate rows based on the \"Company Name\" column\n",
    "df_new_cleaned = df_new.drop_duplicates(subset=[\"Company Name\"])\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "cleaned_file_path = \"Cleaned_Company_List.csv\"  # This will save the file in the same directory\n",
    "df_new_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned file saved as {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2182360d-d693-4758-b184-b0ec7cc44d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
