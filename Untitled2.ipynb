{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "793705f4-04bd-4512-8986-3d516a6b469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched calendar entries have been saved to 'matched_calendar_entries.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_primary_address_part(address):\n",
    "    \"\"\"Extract the primary part of the address, i.e., everything before the first comma, and normalize it.\"\"\"\n",
    "    if pd.isna(address):\n",
    "        return \"\"\n",
    "    primary_part = address.split(',')[0].strip().lower()  # Split the address at the first comma and normalize\n",
    "    return primary_part\n",
    "\n",
    "# Load the data from both CSV files\n",
    "customers = pd.read_csv('770 blank.csv', encoding='utf-8')\n",
    "calendar = pd.read_csv('Calendar Dump.csv', encoding='ISO-8859-1')  # Adjust encoding if necessary\n",
    "\n",
    "# Normalize the addresses in both dataframes to extract the primary part\n",
    "customers['Normalized Address'] = customers['Service Address'].apply(extract_primary_address_part)\n",
    "calendar['Normalized Location'] = calendar['Location'].apply(extract_primary_address_part)\n",
    "\n",
    "# Merge the dataframes based on normalized addresses\n",
    "merged_data = pd.merge(customers, calendar, left_on='Normalized Address', right_on='Normalized Location', how='inner')\n",
    "\n",
    "# Select only the required columns for the output\n",
    "output_data = merged_data[['Account Name', 'Normalized Address', 'Guestlist']]\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "output_data.to_csv('matched_calendar_entries111.csv', index=False)\n",
    "\n",
    "print(\"Matched calendar entries have been saved to 'matched_calendar_entries.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c1136a7-9b4b-4fdd-9cb3-91f734b9e49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Account Name     Normalized Address  \\\n",
      "0        John Pharaon      1464 anton square   \n",
      "1        John Pharaon      1464 anton square   \n",
      "2         Bo Lindgren  118 campbell crescent   \n",
      "3           Sadaf Rai         6932 bilbao ln   \n",
      "4     JENNIFER GORDON    14 lloyd george ave   \n",
      "..                ...                    ...   \n",
      "312       Sean Coster  1958 forest valley dr   \n",
      "313  KAYA TACHE-GREEN        269 sterling rd   \n",
      "314    Michael Caplan       129 invermay ave   \n",
      "315   Hagop Barounian   10 valencia crescent   \n",
      "316        Jerry Wang       15 flax field ln   \n",
      "\n",
      "                                    Email_1  \\\n",
      "0                       jepharaon@gmail.com   \n",
      "1                       jepharaon@gmail.com   \n",
      "2                      aek.rsi647@gmail.com   \n",
      "3                     ahsanrai.ar@gmail.com   \n",
      "4                     jgordon88@hotmail.com   \n",
      "..                                      ...   \n",
      "312       nextlevelconsulting.ali@gmail.com   \n",
      "313                   kayaveassaf@gmail.com   \n",
      "314  nextlevelconsulting.safakish@gmail.com   \n",
      "315  nextlevelconsulting.safakish@gmail.com   \n",
      "316                  wang.jerry94@gmail.com   \n",
      "\n",
      "                                    Email_2 Email_3  \n",
      "0                                      None    None  \n",
      "1                                      None    None  \n",
      "2                        54bossel@gmail.com    None  \n",
      "3                                      None    None  \n",
      "4                                      None    None  \n",
      "..                                      ...     ...  \n",
      "312                        costerse@msn.com    None  \n",
      "313  nextlevelconsulting.safakish@gmail.com    None  \n",
      "314                  alanaspclark@gmail.com    None  \n",
      "315               hagop.barounian@gmail.com    None  \n",
      "316  nextlevelconsulting.safakish@gmail.com    None  \n",
      "\n",
      "[317 rows x 5 columns]\n",
      "Cleaned emails have been saved to 'cleaned_matched_calendar_entries.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df = pd.read_csv('matched_calendar_entries111.csv')\n",
    "\n",
    "def extract_emails(text):\n",
    "    # Ensure the input is a string\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    # Extract email addresses using regex\n",
    "    emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "    return emails\n",
    "\n",
    "# Apply the extraction function to the 'Guestlist' or relevant column\n",
    "df['Emails'] = df['Guestlist'].apply(extract_emails)\n",
    "\n",
    "# Find the maximum number of emails in any single row to determine the number of columns needed\n",
    "max_emails = df['Emails'].str.len().max()\n",
    "\n",
    "# Create new columns for each email\n",
    "for i in range(max_emails):\n",
    "    df[f'Email_{i+1}'] = df['Emails'].apply(lambda x: x[i] if i < len(x) else None)\n",
    "\n",
    "# Drop the original 'Guestlist' and temporary 'Emails' columns\n",
    "df.drop(columns=['Guestlist', 'Emails'], inplace=True)\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv('cleaned_matched_calendar_entries.csv', index=False)\n",
    "\n",
    "print(df)\n",
    "print(\"Cleaned emails have been saved to 'cleaned_matched_calendar_entries.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1774e88c-c5b3-4672-9dad-f6615b2b37c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cleaned data has been saved back to 'cleaned_matched_calendar_entries.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df = pd.read_csv('cleaned_matched_calendar_entries.csv')\n",
    "\n",
    "# Define a function to clean cell data\n",
    "def clean_cell_content(cell):\n",
    "    if isinstance(cell, str):  # Ensure that the cell contains text\n",
    "        if 'nextlevel' in cell.lower() or 'nxtlevel' in cell.lower():\n",
    "            return ''  # Replace content if it contains the specified substrings\n",
    "        return cell\n",
    "    return cell\n",
    "\n",
    "# Apply the cleaning function to all columns in the DataFrame\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].apply(clean_cell_content)\n",
    "\n",
    "# Save the cleaned data back to a CSV file\n",
    "df.to_csv('cleaned_matched_calendar_entries.csv', index=False)\n",
    "\n",
    "print(\"The cleaned data has been saved back to 'cleaned_matched_calendar_entries.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6bc09d9-5d7d-48bf-87ec-576d6651ec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique emails have been saved to 'unique_emails.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df = pd.read_csv('cleaned_matched_calendar_entries.csv')\n",
    "\n",
    "# Assume the email columns are named 'Email_1', 'Email_2', 'Email_3', etc.\n",
    "# Adjust the list of columns based on your actual data structure\n",
    "email_columns = [col for col in df.columns if 'Email' in col]\n",
    "\n",
    "# Collect all emails into a single Series, ignoring NaN values\n",
    "all_emails = pd.concat([df[col].dropna() for col in email_columns]).reset_index(drop=True)\n",
    "\n",
    "# Drop duplicates to get unique emails\n",
    "unique_emails = all_emails.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Create a new DataFrame to save the result\n",
    "email_df = pd.DataFrame(unique_emails, columns=['Unique_Emails'])\n",
    "\n",
    "# Save the unique emails to a new CSV file\n",
    "email_df.to_csv('unique_emails.csv', index=False)\n",
    "\n",
    "print(\"Unique emails have been saved to 'unique_emails.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d414956-3809-48da-9b93-e7fd634a5638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
